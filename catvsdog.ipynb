{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb0c88a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-05T03:57:46.746164Z",
     "iopub.status.busy": "2024-09-05T03:57:46.745295Z",
     "iopub.status.idle": "2024-09-05T13:57:09.207866Z",
     "shell.execute_reply": "2024-09-05T13:57:09.206946Z"
    },
    "papermill": {
     "duration": 35962.468282,
     "end_time": "2024-09-05T13:57:09.210176",
     "exception": false,
     "start_time": "2024-09-05T03:57:46.741894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|███| 352/352 [05:46<00:00,  1.01it/s, accuracy=63, loss=0.652]\r\n",
      "Epoch [1/100], Train Loss: 0.6718, Train Accuracy: 63.04%\r\n",
      "Validation Loss: 0.6462, Validation Accuracy: 64.20%\r\n",
      "New best model saved with Validation Accuracy: 64.20%\r\n",
      "Epoch 2/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=64.3, loss=0.677]\r\n",
      "Epoch [2/100], Train Loss: 0.6340, Train Accuracy: 64.33%\r\n",
      "Validation Loss: 0.6170, Validation Accuracy: 65.32%\r\n",
      "New best model saved with Validation Accuracy: 65.32%\r\n",
      "Epoch 3/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=72.4, loss=0.602]\r\n",
      "Epoch [3/100], Train Loss: 0.5550, Train Accuracy: 72.39%\r\n",
      "Validation Loss: 0.5507, Validation Accuracy: 72.04%\r\n",
      "New best model saved with Validation Accuracy: 72.04%\r\n",
      "Epoch 4/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=76.7, loss=0.604]\r\n",
      "Epoch [4/100], Train Loss: 0.4933, Train Accuracy: 76.73%\r\n",
      "Validation Loss: 0.6977, Validation Accuracy: 69.04%\r\n",
      "Epoch 5/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=81.7, loss=0.602]\r\n",
      "Epoch [5/100], Train Loss: 0.4101, Train Accuracy: 81.69%\r\n",
      "Validation Loss: 0.4981, Validation Accuracy: 77.80%\r\n",
      "New best model saved with Validation Accuracy: 77.80%\r\n",
      "Epoch 6/100: 100%|██| 352/352 [05:39<00:00,  1.04it/s, accuracy=84.1, loss=0.29]\r\n",
      "Epoch [6/100], Train Loss: 0.3634, Train Accuracy: 84.12%\r\n",
      "Validation Loss: 0.8585, Validation Accuracy: 69.92%\r\n",
      "Epoch 7/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=86.6, loss=0.353]\r\n",
      "Epoch [7/100], Train Loss: 0.3113, Train Accuracy: 86.64%\r\n",
      "Validation Loss: 0.6837, Validation Accuracy: 73.76%\r\n",
      "Epoch 8/100: 100%|█| 352/352 [05:38<00:00,  1.04it/s, accuracy=88.6, loss=0.165]\r\n",
      "Epoch [8/100], Train Loss: 0.2711, Train Accuracy: 88.56%\r\n",
      "Validation Loss: 0.2722, Validation Accuracy: 88.40%\r\n",
      "New best model saved with Validation Accuracy: 88.40%\r\n",
      "Epoch 9/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=90.4, loss=0.0431\r\n",
      "Epoch [9/100], Train Loss: 0.2313, Train Accuracy: 90.36%\r\n",
      "Validation Loss: 0.4831, Validation Accuracy: 82.28%\r\n",
      "Epoch 10/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=91.4, loss=0.252\r\n",
      "Epoch [10/100], Train Loss: 0.2033, Train Accuracy: 91.44%\r\n",
      "Validation Loss: 0.2387, Validation Accuracy: 90.96%\r\n",
      "New best model saved with Validation Accuracy: 90.96%\r\n",
      "Epoch 11/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=92.5, loss=0.338\r\n",
      "Epoch [11/100], Train Loss: 0.1831, Train Accuracy: 92.50%\r\n",
      "Validation Loss: 0.2296, Validation Accuracy: 90.12%\r\n",
      "Epoch 12/100: 100%|██| 352/352 [05:40<00:00,  1.03it/s, accuracy=93, loss=0.192]\r\n",
      "Epoch [12/100], Train Loss: 0.1667, Train Accuracy: 93.05%\r\n",
      "Validation Loss: 0.2541, Validation Accuracy: 92.24%\r\n",
      "New best model saved with Validation Accuracy: 92.24%\r\n",
      "Epoch 13/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=93.3, loss=0.168\r\n",
      "Epoch [13/100], Train Loss: 0.1613, Train Accuracy: 93.34%\r\n",
      "Validation Loss: 0.3430, Validation Accuracy: 86.84%\r\n",
      "Epoch 14/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=92.8, loss=0.179\r\n",
      "Epoch [14/100], Train Loss: 0.1714, Train Accuracy: 92.77%\r\n",
      "Validation Loss: 0.1988, Validation Accuracy: 91.92%\r\n",
      "Epoch 15/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=94.4, loss=0.114\r\n",
      "Epoch [15/100], Train Loss: 0.1349, Train Accuracy: 94.42%\r\n",
      "Validation Loss: 0.1836, Validation Accuracy: 93.24%\r\n",
      "New best model saved with Validation Accuracy: 93.24%\r\n",
      "Epoch 16/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=94.8, loss=0.187\r\n",
      "Epoch [16/100], Train Loss: 0.1290, Train Accuracy: 94.76%\r\n",
      "Validation Loss: 0.1847, Validation Accuracy: 92.72%\r\n",
      "Epoch 17/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=95.1, loss=0.205\r\n",
      "Epoch [17/100], Train Loss: 0.1180, Train Accuracy: 95.13%\r\n",
      "Validation Loss: 0.3384, Validation Accuracy: 88.00%\r\n",
      "Epoch 18/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=95.6, loss=0.181\r\n",
      "Epoch [18/100], Train Loss: 0.1095, Train Accuracy: 95.62%\r\n",
      "Validation Loss: 0.3666, Validation Accuracy: 88.20%\r\n",
      "Epoch 19/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=95.7, loss=0.125\r\n",
      "Epoch [19/100], Train Loss: 0.1085, Train Accuracy: 95.69%\r\n",
      "Validation Loss: 0.2249, Validation Accuracy: 91.40%\r\n",
      "Epoch 20/100: 100%|█| 352/352 [05:40<00:00,  1.04it/s, accuracy=96.3, loss=0.113\r\n",
      "Epoch [20/100], Train Loss: 0.0943, Train Accuracy: 96.26%\r\n",
      "Validation Loss: 0.2817, Validation Accuracy: 90.76%\r\n",
      "Epoch 21/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=96.3, loss=0.195\r\n",
      "Epoch [21/100], Train Loss: 0.0919, Train Accuracy: 96.32%\r\n",
      "Validation Loss: 0.1648, Validation Accuracy: 93.36%\r\n",
      "New best model saved with Validation Accuracy: 93.36%\r\n",
      "Epoch 22/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=96.4, loss=0.078\r\n",
      "Epoch [22/100], Train Loss: 0.0867, Train Accuracy: 96.44%\r\n",
      "Validation Loss: 0.8437, Validation Accuracy: 80.72%\r\n",
      "Epoch 23/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=96.7, loss=0.107\r\n",
      "Epoch [23/100], Train Loss: 0.0843, Train Accuracy: 96.70%\r\n",
      "Validation Loss: 0.1499, Validation Accuracy: 94.60%\r\n",
      "New best model saved with Validation Accuracy: 94.60%\r\n",
      "Epoch 24/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=97.4, loss=0.281\r\n",
      "Epoch [24/100], Train Loss: 0.0687, Train Accuracy: 97.36%\r\n",
      "Validation Loss: 0.2752, Validation Accuracy: 90.00%\r\n",
      "Epoch 25/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=97.3, loss=0.103\r\n",
      "Epoch [25/100], Train Loss: 0.0701, Train Accuracy: 97.28%\r\n",
      "Validation Loss: 0.1711, Validation Accuracy: 93.56%\r\n",
      "Epoch 26/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=97.7, loss=0.016\r\n",
      "Epoch [26/100], Train Loss: 0.0602, Train Accuracy: 97.72%\r\n",
      "Validation Loss: 0.2248, Validation Accuracy: 91.64%\r\n",
      "Epoch 27/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=97.8, loss=0.034\r\n",
      "Epoch [27/100], Train Loss: 0.0586, Train Accuracy: 97.80%\r\n",
      "Validation Loss: 0.1847, Validation Accuracy: 93.68%\r\n",
      "Epoch 28/100: 100%|██| 352/352 [05:41<00:00,  1.03it/s, accuracy=98, loss=0.125]\r\n",
      "Epoch [28/100], Train Loss: 0.0537, Train Accuracy: 98.01%\r\n",
      "Validation Loss: 0.3366, Validation Accuracy: 90.52%\r\n",
      "Epoch 29/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=98.2, loss=0.095\r\n",
      "Epoch [29/100], Train Loss: 0.0505, Train Accuracy: 98.18%\r\n",
      "Validation Loss: 0.3005, Validation Accuracy: 92.04%\r\n",
      "Epoch 30/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=98, loss=0.0303]\r\n",
      "Epoch [30/100], Train Loss: 0.0524, Train Accuracy: 98.05%\r\n",
      "Validation Loss: 0.1440, Validation Accuracy: 94.80%\r\n",
      "New best model saved with Validation Accuracy: 94.80%\r\n",
      "Epoch 31/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=98.5, loss=0.005\r\n",
      "Epoch [31/100], Train Loss: 0.0418, Train Accuracy: 98.46%\r\n",
      "Validation Loss: 0.1936, Validation Accuracy: 94.40%\r\n",
      "Epoch 32/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=98.2, loss=0.019\r\n",
      "Epoch [32/100], Train Loss: 0.0473, Train Accuracy: 98.18%\r\n",
      "Validation Loss: 0.1688, Validation Accuracy: 94.92%\r\n",
      "New best model saved with Validation Accuracy: 94.92%\r\n",
      "Epoch 33/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=98.5, loss=0.225\r\n",
      "Epoch [33/100], Train Loss: 0.0377, Train Accuracy: 98.52%\r\n",
      "Validation Loss: 0.6301, Validation Accuracy: 88.00%\r\n",
      "Epoch 34/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=98.5, loss=0.249\r\n",
      "Epoch [34/100], Train Loss: 0.0420, Train Accuracy: 98.48%\r\n",
      "Validation Loss: 0.1683, Validation Accuracy: 94.40%\r\n",
      "Epoch 35/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=98.7, loss=0.010\r\n",
      "Epoch [35/100], Train Loss: 0.0363, Train Accuracy: 98.74%\r\n",
      "Validation Loss: 0.1984, Validation Accuracy: 94.76%\r\n",
      "Epoch 36/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=98.7, loss=0.012\r\n",
      "Epoch [36/100], Train Loss: 0.0347, Train Accuracy: 98.72%\r\n",
      "Validation Loss: 0.2175, Validation Accuracy: 93.88%\r\n",
      "Epoch 37/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=98.9, loss=0.011\r\n",
      "Epoch [37/100], Train Loss: 0.0308, Train Accuracy: 98.89%\r\n",
      "Validation Loss: 0.2231, Validation Accuracy: 93.48%\r\n",
      "Epoch 38/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=98.9, loss=0.061\r\n",
      "Epoch [38/100], Train Loss: 0.0291, Train Accuracy: 98.88%\r\n",
      "Validation Loss: 0.3117, Validation Accuracy: 93.20%\r\n",
      "Epoch 39/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=98.7, loss=0.005\r\n",
      "Epoch [39/100], Train Loss: 0.0340, Train Accuracy: 98.73%\r\n",
      "Validation Loss: 0.2412, Validation Accuracy: 93.84%\r\n",
      "Epoch 40/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99, loss=0.0154]\r\n",
      "Epoch [40/100], Train Loss: 0.0281, Train Accuracy: 98.98%\r\n",
      "Validation Loss: 0.3457, Validation Accuracy: 91.44%\r\n",
      "Epoch 41/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99, loss=0.0475]\r\n",
      "Epoch [41/100], Train Loss: 0.0299, Train Accuracy: 99.00%\r\n",
      "Validation Loss: 0.1806, Validation Accuracy: 94.64%\r\n",
      "Epoch 42/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.3, loss=0.031\r\n",
      "Epoch [42/100], Train Loss: 0.0211, Train Accuracy: 99.27%\r\n",
      "Validation Loss: 0.3829, Validation Accuracy: 92.28%\r\n",
      "Epoch 43/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=98.9, loss=0.040\r\n",
      "Epoch [43/100], Train Loss: 0.0291, Train Accuracy: 98.95%\r\n",
      "Validation Loss: 0.1853, Validation Accuracy: 94.24%\r\n",
      "Epoch 44/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.4, loss=0.113\r\n",
      "Epoch [44/100], Train Loss: 0.0158, Train Accuracy: 99.44%\r\n",
      "Validation Loss: 0.1925, Validation Accuracy: 94.64%\r\n",
      "Epoch 45/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=99.1, loss=0.000\r\n",
      "Epoch [45/100], Train Loss: 0.0247, Train Accuracy: 99.13%\r\n",
      "Validation Loss: 0.1753, Validation Accuracy: 95.04%\r\n",
      "New best model saved with Validation Accuracy: 95.04%\r\n",
      "Epoch 46/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.2, loss=0.002\r\n",
      "Epoch [46/100], Train Loss: 0.0207, Train Accuracy: 99.25%\r\n",
      "Validation Loss: 0.1994, Validation Accuracy: 94.84%\r\n",
      "Epoch 47/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99, loss=0.00961\r\n",
      "Epoch [47/100], Train Loss: 0.0260, Train Accuracy: 99.04%\r\n",
      "Validation Loss: 0.1499, Validation Accuracy: 95.08%\r\n",
      "New best model saved with Validation Accuracy: 95.08%\r\n",
      "Epoch 48/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=99.4, loss=0.005\r\n",
      "Epoch [48/100], Train Loss: 0.0158, Train Accuracy: 99.43%\r\n",
      "Validation Loss: 0.2822, Validation Accuracy: 94.24%\r\n",
      "Epoch 49/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=99.2, loss=0.022\r\n",
      "Epoch [49/100], Train Loss: 0.0229, Train Accuracy: 99.18%\r\n",
      "Validation Loss: 0.2050, Validation Accuracy: 93.96%\r\n",
      "Epoch 50/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=99.5, loss=0.014\r\n",
      "Epoch [50/100], Train Loss: 0.0149, Train Accuracy: 99.46%\r\n",
      "Validation Loss: 0.2075, Validation Accuracy: 94.96%\r\n",
      "Epoch 51/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=99.3, loss=0.006\r\n",
      "Epoch [51/100], Train Loss: 0.0203, Train Accuracy: 99.29%\r\n",
      "Validation Loss: 0.1837, Validation Accuracy: 95.00%\r\n",
      "Epoch 52/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.4, loss=0.024\r\n",
      "Epoch [52/100], Train Loss: 0.0165, Train Accuracy: 99.41%\r\n",
      "Validation Loss: 0.1812, Validation Accuracy: 94.92%\r\n",
      "Epoch 53/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.5, loss=0.115\r\n",
      "Epoch [53/100], Train Loss: 0.0151, Train Accuracy: 99.51%\r\n",
      "Validation Loss: 0.1920, Validation Accuracy: 94.36%\r\n",
      "Epoch 54/100: 100%|█| 352/352 [05:40<00:00,  1.04it/s, accuracy=99.5, loss=0.001\r\n",
      "Epoch [54/100], Train Loss: 0.0147, Train Accuracy: 99.52%\r\n",
      "Validation Loss: 0.2331, Validation Accuracy: 93.88%\r\n",
      "Epoch 55/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.3, loss=0.002\r\n",
      "Epoch [55/100], Train Loss: 0.0208, Train Accuracy: 99.30%\r\n",
      "Validation Loss: 0.1976, Validation Accuracy: 94.68%\r\n",
      "Epoch 56/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=99.5, loss=0.009\r\n",
      "Epoch [56/100], Train Loss: 0.0150, Train Accuracy: 99.50%\r\n",
      "Validation Loss: 0.1839, Validation Accuracy: 95.68%\r\n",
      "New best model saved with Validation Accuracy: 95.68%\r\n",
      "Epoch 57/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.4, loss=0.002\r\n",
      "Epoch [57/100], Train Loss: 0.0182, Train Accuracy: 99.36%\r\n",
      "Validation Loss: 0.1698, Validation Accuracy: 95.68%\r\n",
      "Epoch 58/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.8, loss=0.009\r\n",
      "Epoch [58/100], Train Loss: 0.0073, Train Accuracy: 99.80%\r\n",
      "Validation Loss: 0.3150, Validation Accuracy: 93.72%\r\n",
      "Epoch 59/100: 100%|█| 352/352 [05:39<00:00,  1.04it/s, accuracy=99.1, loss=0.000\r\n",
      "Epoch [59/100], Train Loss: 0.0242, Train Accuracy: 99.13%\r\n",
      "Validation Loss: 0.2039, Validation Accuracy: 94.76%\r\n",
      "Epoch 60/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.7, loss=0.001\r\n",
      "Epoch [60/100], Train Loss: 0.0089, Train Accuracy: 99.69%\r\n",
      "Validation Loss: 0.2233, Validation Accuracy: 94.88%\r\n",
      "Epoch 61/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.4, loss=9.49e\r\n",
      "Epoch [61/100], Train Loss: 0.0163, Train Accuracy: 99.44%\r\n",
      "Validation Loss: 0.2609, Validation Accuracy: 93.44%\r\n",
      "Epoch 62/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.6, loss=0.001\r\n",
      "Epoch [62/100], Train Loss: 0.0110, Train Accuracy: 99.64%\r\n",
      "Validation Loss: 0.2049, Validation Accuracy: 95.44%\r\n",
      "Epoch 63/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.3, loss=0.012\r\n",
      "Epoch [63/100], Train Loss: 0.0181, Train Accuracy: 99.33%\r\n",
      "Validation Loss: 0.2715, Validation Accuracy: 94.72%\r\n",
      "Epoch 64/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.6, loss=0.002\r\n",
      "Epoch [64/100], Train Loss: 0.0123, Train Accuracy: 99.59%\r\n",
      "Validation Loss: 0.2208, Validation Accuracy: 95.36%\r\n",
      "Epoch 65/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.4, loss=0.134\r\n",
      "Epoch [65/100], Train Loss: 0.0163, Train Accuracy: 99.40%\r\n",
      "Validation Loss: 0.2773, Validation Accuracy: 93.72%\r\n",
      "Epoch 66/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.7, loss=3.55e\r\n",
      "Epoch [66/100], Train Loss: 0.0093, Train Accuracy: 99.67%\r\n",
      "Validation Loss: 0.2340, Validation Accuracy: 94.60%\r\n",
      "Epoch 67/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.5, loss=0.012\r\n",
      "Epoch [67/100], Train Loss: 0.0155, Train Accuracy: 99.48%\r\n",
      "Validation Loss: 0.1921, Validation Accuracy: 95.56%\r\n",
      "Epoch 68/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.6, loss=0.002\r\n",
      "Epoch [68/100], Train Loss: 0.0131, Train Accuracy: 99.60%\r\n",
      "Validation Loss: 0.1969, Validation Accuracy: 94.64%\r\n",
      "Epoch 69/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.7, loss=0.124\r\n",
      "Epoch [69/100], Train Loss: 0.0085, Train Accuracy: 99.75%\r\n",
      "Validation Loss: 0.2158, Validation Accuracy: 94.88%\r\n",
      "Epoch 70/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.5, loss=0.056\r\n",
      "Epoch [70/100], Train Loss: 0.0145, Train Accuracy: 99.54%\r\n",
      "Validation Loss: 0.2070, Validation Accuracy: 95.20%\r\n",
      "Epoch 71/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.7, loss=0.001\r\n",
      "Epoch [71/100], Train Loss: 0.0076, Train Accuracy: 99.75%\r\n",
      "Validation Loss: 0.3336, Validation Accuracy: 94.44%\r\n",
      "Epoch 72/100: 100%|█| 352/352 [05:42<00:00,  1.03it/s, accuracy=99.7, loss=0.004\r\n",
      "Epoch [72/100], Train Loss: 0.0077, Train Accuracy: 99.71%\r\n",
      "Validation Loss: 0.3016, Validation Accuracy: 94.76%\r\n",
      "Epoch 73/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.6, loss=0.000\r\n",
      "Epoch [73/100], Train Loss: 0.0110, Train Accuracy: 99.64%\r\n",
      "Validation Loss: 0.8640, Validation Accuracy: 86.56%\r\n",
      "Epoch 74/100: 100%|█| 352/352 [05:42<00:00,  1.03it/s, accuracy=99.5, loss=0.000\r\n",
      "Epoch [74/100], Train Loss: 0.0159, Train Accuracy: 99.45%\r\n",
      "Validation Loss: 0.2139, Validation Accuracy: 94.88%\r\n",
      "Epoch 75/100: 100%|█| 352/352 [05:42<00:00,  1.03it/s, accuracy=99.9, loss=7.86e\r\n",
      "Epoch [75/100], Train Loss: 0.0043, Train Accuracy: 99.85%\r\n",
      "Validation Loss: 0.2328, Validation Accuracy: 95.16%\r\n",
      "Epoch 76/100: 100%|█| 352/352 [05:42<00:00,  1.03it/s, accuracy=99.9, loss=0.018\r\n",
      "Epoch [76/100], Train Loss: 0.0030, Train Accuracy: 99.91%\r\n",
      "Validation Loss: 0.3913, Validation Accuracy: 94.48%\r\n",
      "Epoch 77/100: 100%|█| 352/352 [05:42<00:00,  1.03it/s, accuracy=99.5, loss=0.017\r\n",
      "Epoch [77/100], Train Loss: 0.0142, Train Accuracy: 99.51%\r\n",
      "Validation Loss: 0.2224, Validation Accuracy: 94.84%\r\n",
      "Epoch 78/100: 100%|█| 352/352 [05:42<00:00,  1.03it/s, accuracy=99.7, loss=0.006\r\n",
      "Epoch [78/100], Train Loss: 0.0082, Train Accuracy: 99.72%\r\n",
      "Validation Loss: 0.2444, Validation Accuracy: 95.04%\r\n",
      "Epoch 79/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.8, loss=0.000\r\n",
      "Epoch [79/100], Train Loss: 0.0058, Train Accuracy: 99.78%\r\n",
      "Validation Loss: 0.3438, Validation Accuracy: 93.44%\r\n",
      "Epoch 80/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.6, loss=0.004\r\n",
      "Epoch [80/100], Train Loss: 0.0126, Train Accuracy: 99.62%\r\n",
      "Validation Loss: 0.2335, Validation Accuracy: 95.52%\r\n",
      "Epoch 81/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.8, loss=0.000\r\n",
      "Epoch [81/100], Train Loss: 0.0056, Train Accuracy: 99.82%\r\n",
      "Validation Loss: 0.2912, Validation Accuracy: 94.00%\r\n",
      "Epoch 82/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.6, loss=0.004\r\n",
      "Epoch [82/100], Train Loss: 0.0116, Train Accuracy: 99.58%\r\n",
      "Validation Loss: 0.2867, Validation Accuracy: 94.28%\r\n",
      "Epoch 83/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.8, loss=0.001\r\n",
      "Epoch [83/100], Train Loss: 0.0070, Train Accuracy: 99.78%\r\n",
      "Validation Loss: 0.2149, Validation Accuracy: 95.40%\r\n",
      "Epoch 84/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.6, loss=0.010\r\n",
      "Epoch [84/100], Train Loss: 0.0109, Train Accuracy: 99.62%\r\n",
      "Validation Loss: 0.2333, Validation Accuracy: 94.36%\r\n",
      "Epoch 85/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=100, loss=4.8e-5\r\n",
      "Epoch [85/100], Train Loss: 0.0017, Train Accuracy: 99.97%\r\n",
      "Validation Loss: 0.2755, Validation Accuracy: 95.44%\r\n",
      "Epoch 86/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.8, loss=0.000\r\n",
      "Epoch [86/100], Train Loss: 0.0065, Train Accuracy: 99.76%\r\n",
      "Validation Loss: 0.2978, Validation Accuracy: 93.04%\r\n",
      "Epoch 87/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.5, loss=0.005\r\n",
      "Epoch [87/100], Train Loss: 0.0148, Train Accuracy: 99.50%\r\n",
      "Validation Loss: 0.3389, Validation Accuracy: 94.00%\r\n",
      "Epoch 88/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.7, loss=0.000\r\n",
      "Epoch [88/100], Train Loss: 0.0101, Train Accuracy: 99.67%\r\n",
      "Validation Loss: 0.2119, Validation Accuracy: 95.68%\r\n",
      "Epoch 89/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.9, loss=0.000\r\n",
      "Epoch [89/100], Train Loss: 0.0029, Train Accuracy: 99.91%\r\n",
      "Validation Loss: 0.2263, Validation Accuracy: 95.20%\r\n",
      "Epoch 90/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=100, loss=2.52e-\r\n",
      "Epoch [90/100], Train Loss: 0.0016, Train Accuracy: 99.96%\r\n",
      "Validation Loss: 0.2908, Validation Accuracy: 95.68%\r\n",
      "Epoch 91/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.6, loss=0.001\r\n",
      "Epoch [91/100], Train Loss: 0.0112, Train Accuracy: 99.61%\r\n",
      "Validation Loss: 0.2460, Validation Accuracy: 94.16%\r\n",
      "Epoch 92/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.7, loss=0.000\r\n",
      "Epoch [92/100], Train Loss: 0.0086, Train Accuracy: 99.68%\r\n",
      "Validation Loss: 0.2477, Validation Accuracy: 95.20%\r\n",
      "Epoch 93/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.4, loss=0.000\r\n",
      "Epoch [93/100], Train Loss: 0.0169, Train Accuracy: 99.40%\r\n",
      "Validation Loss: 0.2459, Validation Accuracy: 95.24%\r\n",
      "Epoch 94/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.7, loss=0.000\r\n",
      "Epoch [94/100], Train Loss: 0.0094, Train Accuracy: 99.70%\r\n",
      "Validation Loss: 0.2327, Validation Accuracy: 95.16%\r\n",
      "Epoch 95/100: 100%|█| 352/352 [05:42<00:00,  1.03it/s, accuracy=99.8, loss=0.000\r\n",
      "Epoch [95/100], Train Loss: 0.0070, Train Accuracy: 99.75%\r\n",
      "Validation Loss: 0.2881, Validation Accuracy: 95.04%\r\n",
      "Epoch 96/100: 100%|█| 352/352 [05:42<00:00,  1.03it/s, accuracy=99.8, loss=0.000\r\n",
      "Epoch [96/100], Train Loss: 0.0047, Train Accuracy: 99.82%\r\n",
      "Validation Loss: 0.2984, Validation Accuracy: 94.96%\r\n",
      "Epoch 97/100: 100%|█| 352/352 [05:40<00:00,  1.03it/s, accuracy=99.8, loss=0.000\r\n",
      "Epoch [97/100], Train Loss: 0.0065, Train Accuracy: 99.78%\r\n",
      "Validation Loss: 0.2548, Validation Accuracy: 95.20%\r\n",
      "Epoch 98/100: 100%|█| 352/352 [05:42<00:00,  1.03it/s, accuracy=99.8, loss=5.62e\r\n",
      "Epoch [98/100], Train Loss: 0.0060, Train Accuracy: 99.79%\r\n",
      "Validation Loss: 0.3177, Validation Accuracy: 93.84%\r\n",
      "Epoch 99/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.8, loss=1.49e\r\n",
      "Epoch [99/100], Train Loss: 0.0063, Train Accuracy: 99.80%\r\n",
      "Validation Loss: 0.2489, Validation Accuracy: 95.60%\r\n",
      "Epoch 100/100: 100%|█| 352/352 [05:41<00:00,  1.03it/s, accuracy=99.8, loss=0.00\r\n",
      "Epoch [100/100], Train Loss: 0.0049, Train Accuracy: 99.82%\r\n",
      "Validation Loss: 0.2350, Validation Accuracy: 95.76%\r\n",
      "New best model saved with Validation Accuracy: 95.76%\r\n",
      "/kaggle/input/resnet2/pytorch/default/1/catvsdog/test.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/input/resnet2/pytorch/default/1/catvsdog/test.py\", line 64, in <module>\r\n",
      "    model = load_model(model_path, device)\r\n",
      "  File \"/kaggle/input/resnet2/pytorch/default/1/catvsdog/test.py\", line 13, in load_model\r\n",
      "    model.load_state_dict(torch.load(model_path, map_location=device))\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 2215, in load_state_dict\r\n",
      "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\r\n",
      "RuntimeError: Error(s) in loading state_dict for ResNet:\r\n",
      "\tUnexpected key(s) in state_dict: \"layer2.4.conv1.weight\", \"layer2.4.conv1.bias\", \"layer2.4.batch_norm1.weight\", \"layer2.4.batch_norm1.bias\", \"layer2.4.batch_norm1.running_mean\", \"layer2.4.batch_norm1.running_var\", \"layer2.4.batch_norm1.num_batches_tracked\", \"layer2.4.conv2.weight\", \"layer2.4.conv2.bias\", \"layer2.4.batch_norm2.weight\", \"layer2.4.batch_norm2.bias\", \"layer2.4.batch_norm2.running_mean\", \"layer2.4.batch_norm2.running_var\", \"layer2.4.batch_norm2.num_batches_tracked\", \"layer2.4.conv3.weight\", \"layer2.4.conv3.bias\", \"layer2.4.batch_norm3.weight\", \"layer2.4.batch_norm3.bias\", \"layer2.4.batch_norm3.running_mean\", \"layer2.4.batch_norm3.running_var\", \"layer2.4.batch_norm3.num_batches_tracked\", \"layer2.5.conv1.weight\", \"layer2.5.conv1.bias\", \"layer2.5.batch_norm1.weight\", \"layer2.5.batch_norm1.bias\", \"layer2.5.batch_norm1.running_mean\", \"layer2.5.batch_norm1.running_var\", \"layer2.5.batch_norm1.num_batches_tracked\", \"layer2.5.conv2.weight\", \"layer2.5.conv2.bias\", \"layer2.5.batch_norm2.weight\", \"layer2.5.batch_norm2.bias\", \"layer2.5.batch_norm2.running_mean\", \"layer2.5.batch_norm2.running_var\", \"layer2.5.batch_norm2.num_batches_tracked\", \"layer2.5.conv3.weight\", \"layer2.5.conv3.bias\", \"layer2.5.batch_norm3.weight\", \"layer2.5.batch_norm3.bias\", \"layer2.5.batch_norm3.running_mean\", \"layer2.5.batch_norm3.running_var\", \"layer2.5.batch_norm3.num_batches_tracked\", \"layer2.6.conv1.weight\", \"layer2.6.conv1.bias\", \"layer2.6.batch_norm1.weight\", \"layer2.6.batch_norm1.bias\", \"layer2.6.batch_norm1.running_mean\", \"layer2.6.batch_norm1.running_var\", \"layer2.6.batch_norm1.num_batches_tracked\", \"layer2.6.conv2.weight\", \"layer2.6.conv2.bias\", \"layer2.6.batch_norm2.weight\", \"layer2.6.batch_norm2.bias\", \"layer2.6.batch_norm2.running_mean\", \"layer2.6.batch_norm2.running_var\", \"layer2.6.batch_norm2.num_batches_tracked\", \"layer2.6.conv3.weight\", \"layer2.6.conv3.bias\", \"layer2.6.batch_norm3.weight\", \"layer2.6.batch_norm3.bias\", \"layer2.6.batch_norm3.running_mean\", \"layer2.6.batch_norm3.running_var\", \"layer2.6.batch_norm3.num_batches_tracked\", \"layer2.7.conv1.weight\", \"layer2.7.conv1.bias\", \"layer2.7.batch_norm1.weight\", \"layer2.7.batch_norm1.bias\", \"layer2.7.batch_norm1.running_mean\", \"layer2.7.batch_norm1.running_var\", \"layer2.7.batch_norm1.num_batches_tracked\", \"layer2.7.conv2.weight\", \"layer2.7.conv2.bias\", \"layer2.7.batch_norm2.weight\", \"layer2.7.batch_norm2.bias\", \"layer2.7.batch_norm2.running_mean\", \"layer2.7.batch_norm2.running_var\", \"layer2.7.batch_norm2.num_batches_tracked\", \"layer2.7.conv3.weight\", \"layer2.7.conv3.bias\", \"layer2.7.batch_norm3.weight\", \"layer2.7.batch_norm3.bias\", \"layer2.7.batch_norm3.running_mean\", \"layer2.7.batch_norm3.running_var\", \"layer2.7.batch_norm3.num_batches_tracked\", \"layer3.6.conv1.weight\", \"layer3.6.conv1.bias\", \"layer3.6.batch_norm1.weight\", \"layer3.6.batch_norm1.bias\", \"layer3.6.batch_norm1.running_mean\", \"layer3.6.batch_norm1.running_var\", \"layer3.6.batch_norm1.num_batches_tracked\", \"layer3.6.conv2.weight\", \"layer3.6.conv2.bias\", \"layer3.6.batch_norm2.weight\", \"layer3.6.batch_norm2.bias\", \"layer3.6.batch_norm2.running_mean\", \"layer3.6.batch_norm2.running_var\", \"layer3.6.batch_norm2.num_batches_tracked\", \"layer3.6.conv3.weight\", \"layer3.6.conv3.bias\", \"layer3.6.batch_norm3.weight\", \"layer3.6.batch_norm3.bias\", \"layer3.6.batch_norm3.running_mean\", \"layer3.6.batch_norm3.running_var\", \"layer3.6.batch_norm3.num_batches_tracked\", \"layer3.7.conv1.weight\", \"layer3.7.conv1.bias\", \"layer3.7.batch_norm1.weight\", \"layer3.7.batch_norm1.bias\", \"layer3.7.batch_norm1.running_mean\", \"layer3.7.batch_norm1.running_var\", \"layer3.7.batch_norm1.num_batches_tracked\", \"layer3.7.conv2.weight\", \"layer3.7.conv2.bias\", \"layer3.7.batch_norm2.weight\", \"layer3.7.batch_norm2.bias\", \"layer3.7.batch_norm2.running_mean\", \"layer3.7.batch_norm2.running_var\", \"layer3.7.batch_norm2.num_batches_tracked\", \"layer3.7.conv3.weight\", \"layer3.7.conv3.bias\", \"layer3.7.batch_norm3.weight\", \"layer3.7.batch_norm3.bias\", \"layer3.7.batch_norm3.running_mean\", \"layer3.7.batch_norm3.running_var\", \"layer3.7.batch_norm3.num_batches_tracked\", \"layer3.8.conv1.weight\", \"layer3.8.conv1.bias\", \"layer3.8.batch_norm1.weight\", \"layer3.8.batch_norm1.bias\", \"layer3.8.batch_norm1.running_mean\", \"layer3.8.batch_norm1.running_var\", \"layer3.8.batch_norm1.num_batches_tracked\", \"layer3.8.conv2.weight\", \"layer3.8.conv2.bias\", \"layer3.8.batch_norm2.weight\", \"layer3.8.batch_norm2.bias\", \"layer3.8.batch_norm2.running_mean\", \"layer3.8.batch_norm2.running_var\", \"layer3.8.batch_norm2.num_batches_tracked\", \"layer3.8.conv3.weight\", \"layer3.8.conv3.bias\", \"layer3.8.batch_norm3.weight\", \"layer3.8.batch_norm3.bias\", \"layer3.8.batch_norm3.running_mean\", \"layer3.8.batch_norm3.running_var\", \"layer3.8.batch_norm3.num_batches_tracked\", \"layer3.9.conv1.weight\", \"layer3.9.conv1.bias\", \"layer3.9.batch_norm1.weight\", \"layer3.9.batch_norm1.bias\", \"layer3.9.batch_norm1.running_mean\", \"layer3.9.batch_norm1.running_var\", \"layer3.9.batch_norm1.num_batches_tracked\", \"layer3.9.conv2.weight\", \"layer3.9.conv2.bias\", \"layer3.9.batch_norm2.weight\", \"layer3.9.batch_norm2.bias\", \"layer3.9.batch_norm2.running_mean\", \"layer3.9.batch_norm2.running_var\", \"layer3.9.batch_norm2.num_batches_tracked\", \"layer3.9.conv3.weight\", \"layer3.9.conv3.bias\", \"layer3.9.batch_norm3.weight\", \"layer3.9.batch_norm3.bias\", \"layer3.9.batch_norm3.running_mean\", \"layer3.9.batch_norm3.running_var\", \"layer3.9.batch_norm3.num_batches_tracked\", \"layer3.10.conv1.weight\", \"layer3.10.conv1.bias\", \"layer3.10.batch_norm1.weight\", \"layer3.10.batch_norm1.bias\", \"layer3.10.batch_norm1.running_mean\", \"layer3.10.batch_norm1.running_var\", \"layer3.10.batch_norm1.num_batches_tracked\", \"layer3.10.conv2.weight\", \"layer3.10.conv2.bias\", \"layer3.10.batch_norm2.weight\", \"layer3.10.batch_norm2.bias\", \"layer3.10.batch_norm2.running_mean\", \"layer3.10.batch_norm2.running_var\", \"layer3.10.batch_norm2.num_batches_tracked\", \"layer3.10.conv3.weight\", \"layer3.10.conv3.bias\", \"layer3.10.batch_norm3.weight\", \"layer3.10.batch_norm3.bias\", \"layer3.10.batch_norm3.running_mean\", \"layer3.10.batch_norm3.running_var\", \"layer3.10.batch_norm3.num_batches_tracked\", \"layer3.11.conv1.weight\", \"layer3.11.conv1.bias\", \"layer3.11.batch_norm1.weight\", \"layer3.11.batch_norm1.bias\", \"layer3.11.batch_norm1.running_mean\", \"layer3.11.batch_norm1.running_var\", \"layer3.11.batch_norm1.num_batches_tracked\", \"layer3.11.conv2.weight\", \"layer3.11.conv2.bias\", \"layer3.11.batch_norm2.weight\", \"layer3.11.batch_norm2.bias\", \"layer3.11.batch_norm2.running_mean\", \"layer3.11.batch_norm2.running_var\", \"layer3.11.batch_norm2.num_batches_tracked\", \"layer3.11.conv3.weight\", \"layer3.11.conv3.bias\", \"layer3.11.batch_norm3.weight\", \"layer3.11.batch_norm3.bias\", \"layer3.11.batch_norm3.running_mean\", \"layer3.11.batch_norm3.running_var\", \"layer3.11.batch_norm3.num_batches_tracked\", \"layer3.12.conv1.weight\", \"layer3.12.conv1.bias\", \"layer3.12.batch_norm1.weight\", \"layer3.12.batch_norm1.bias\", \"layer3.12.batch_norm1.running_mean\", \"layer3.12.batch_norm1.running_var\", \"layer3.12.batch_norm1.num_batches_tracked\", \"layer3.12.conv2.weight\", \"layer3.12.conv2.bias\", \"layer3.12.batch_norm2.weight\", \"layer3.12.batch_norm2.bias\", \"layer3.12.batch_norm2.running_mean\", \"layer3.12.batch_norm2.running_var\", \"layer3.12.batch_norm2.num_batches_tracked\", \"layer3.12.conv3.weight\", \"layer3.12.conv3.bias\", \"layer3.12.batch_norm3.weight\", \"layer3.12.batch_norm3.bias\", \"layer3.12.batch_norm3.running_mean\", \"layer3.12.batch_norm3.running_var\", \"layer3.12.batch_norm3.num_batches_tracked\", \"layer3.13.conv1.weight\", \"layer3.13.conv1.bias\", \"layer3.13.batch_norm1.weight\", \"layer3.13.batch_norm1.bias\", \"layer3.13.batch_norm1.running_mean\", \"layer3.13.batch_norm1.running_var\", \"layer3.13.batch_norm1.num_batches_tracked\", \"layer3.13.conv2.weight\", \"layer3.13.conv2.bias\", \"layer3.13.batch_norm2.weight\", \"layer3.13.batch_norm2.bias\", \"layer3.13.batch_norm2.running_mean\", \"layer3.13.batch_norm2.running_var\", \"layer3.13.batch_norm2.num_batches_tracked\", \"layer3.13.conv3.weight\", \"layer3.13.conv3.bias\", \"layer3.13.batch_norm3.weight\", \"layer3.13.batch_norm3.bias\", \"layer3.13.batch_norm3.running_mean\", \"layer3.13.batch_norm3.running_var\", \"layer3.13.batch_norm3.num_batches_tracked\", \"layer3.14.conv1.weight\", \"layer3.14.conv1.bias\", \"layer3.14.batch_norm1.weight\", \"layer3.14.batch_norm1.bias\", \"layer3.14.batch_norm1.running_mean\", \"layer3.14.batch_norm1.running_var\", \"layer3.14.batch_norm1.num_batches_tracked\", \"layer3.14.conv2.weight\", \"layer3.14.conv2.bias\", \"layer3.14.batch_norm2.weight\", \"layer3.14.batch_norm2.bias\", \"layer3.14.batch_norm2.running_mean\", \"layer3.14.batch_norm2.running_var\", \"layer3.14.batch_norm2.num_batches_tracked\", \"layer3.14.conv3.weight\", \"layer3.14.conv3.bias\", \"layer3.14.batch_norm3.weight\", \"layer3.14.batch_norm3.bias\", \"layer3.14.batch_norm3.running_mean\", \"layer3.14.batch_norm3.running_var\", \"layer3.14.batch_norm3.num_batches_tracked\", \"layer3.15.conv1.weight\", \"layer3.15.conv1.bias\", \"layer3.15.batch_norm1.weight\", \"layer3.15.batch_norm1.bias\", \"layer3.15.batch_norm1.running_mean\", \"layer3.15.batch_norm1.running_var\", \"layer3.15.batch_norm1.num_batches_tracked\", \"layer3.15.conv2.weight\", \"layer3.15.conv2.bias\", \"layer3.15.batch_norm2.weight\", \"layer3.15.batch_norm2.bias\", \"layer3.15.batch_norm2.running_mean\", \"layer3.15.batch_norm2.running_var\", \"layer3.15.batch_norm2.num_batches_tracked\", \"layer3.15.conv3.weight\", \"layer3.15.conv3.bias\", \"layer3.15.batch_norm3.weight\", \"layer3.15.batch_norm3.bias\", \"layer3.15.batch_norm3.running_mean\", \"layer3.15.batch_norm3.running_var\", \"layer3.15.batch_norm3.num_batches_tracked\", \"layer3.16.conv1.weight\", \"layer3.16.conv1.bias\", \"layer3.16.batch_norm1.weight\", \"layer3.16.batch_norm1.bias\", \"layer3.16.batch_norm1.running_mean\", \"layer3.16.batch_norm1.running_var\", \"layer3.16.batch_norm1.num_batches_tracked\", \"layer3.16.conv2.weight\", \"layer3.16.conv2.bias\", \"layer3.16.batch_norm2.weight\", \"layer3.16.batch_norm2.bias\", \"layer3.16.batch_norm2.running_mean\", \"layer3.16.batch_norm2.running_var\", \"layer3.16.batch_norm2.num_batches_tracked\", \"layer3.16.conv3.weight\", \"layer3.16.conv3.bias\", \"layer3.16.batch_norm3.weight\", \"layer3.16.batch_norm3.bias\", \"layer3.16.batch_norm3.running_mean\", \"layer3.16.batch_norm3.running_var\", \"layer3.16.batch_norm3.num_batches_tracked\", \"layer3.17.conv1.weight\", \"layer3.17.conv1.bias\", \"layer3.17.batch_norm1.weight\", \"layer3.17.batch_norm1.bias\", \"layer3.17.batch_norm1.running_mean\", \"layer3.17.batch_norm1.running_var\", \"layer3.17.batch_norm1.num_batches_tracked\", \"layer3.17.conv2.weight\", \"layer3.17.conv2.bias\", \"layer3.17.batch_norm2.weight\", \"layer3.17.batch_norm2.bias\", \"layer3.17.batch_norm2.running_mean\", \"layer3.17.batch_norm2.running_var\", \"layer3.17.batch_norm2.num_batches_tracked\", \"layer3.17.conv3.weight\", \"layer3.17.conv3.bias\", \"layer3.17.batch_norm3.weight\", \"layer3.17.batch_norm3.bias\", \"layer3.17.batch_norm3.running_mean\", \"layer3.17.batch_norm3.running_var\", \"layer3.17.batch_norm3.num_batches_tracked\", \"layer3.18.conv1.weight\", \"layer3.18.conv1.bias\", \"layer3.18.batch_norm1.weight\", \"layer3.18.batch_norm1.bias\", \"layer3.18.batch_norm1.running_mean\", \"layer3.18.batch_norm1.running_var\", \"layer3.18.batch_norm1.num_batches_tracked\", \"layer3.18.conv2.weight\", \"layer3.18.conv2.bias\", \"layer3.18.batch_norm2.weight\", \"layer3.18.batch_norm2.bias\", \"layer3.18.batch_norm2.running_mean\", \"layer3.18.batch_norm2.running_var\", \"layer3.18.batch_norm2.num_batches_tracked\", \"layer3.18.conv3.weight\", \"layer3.18.conv3.bias\", \"layer3.18.batch_norm3.weight\", \"layer3.18.batch_norm3.bias\", \"layer3.18.batch_norm3.running_mean\", \"layer3.18.batch_norm3.running_var\", \"layer3.18.batch_norm3.num_batches_tracked\", \"layer3.19.conv1.weight\", \"layer3.19.conv1.bias\", \"layer3.19.batch_norm1.weight\", \"layer3.19.batch_norm1.bias\", \"layer3.19.batch_norm1.running_mean\", \"layer3.19.batch_norm1.running_var\", \"layer3.19.batch_norm1.num_batches_tracked\", \"layer3.19.conv2.weight\", \"layer3.19.conv2.bias\", \"layer3.19.batch_norm2.weight\", \"layer3.19.batch_norm2.bias\", \"layer3.19.batch_norm2.running_mean\", \"layer3.19.batch_norm2.running_var\", \"layer3.19.batch_norm2.num_batches_tracked\", \"layer3.19.conv3.weight\", \"layer3.19.conv3.bias\", \"layer3.19.batch_norm3.weight\", \"layer3.19.batch_norm3.bias\", \"layer3.19.batch_norm3.running_mean\", \"layer3.19.batch_norm3.running_var\", \"layer3.19.batch_norm3.num_batches_tracked\", \"layer3.20.conv1.weight\", \"layer3.20.conv1.bias\", \"layer3.20.batch_norm1.weight\", \"layer3.20.batch_norm1.bias\", \"layer3.20.batch_norm1.running_mean\", \"layer3.20.batch_norm1.running_var\", \"layer3.20.batch_norm1.num_batches_tracked\", \"layer3.20.conv2.weight\", \"layer3.20.conv2.bias\", \"layer3.20.batch_norm2.weight\", \"layer3.20.batch_norm2.bias\", \"layer3.20.batch_norm2.running_mean\", \"layer3.20.batch_norm2.running_var\", \"layer3.20.batch_norm2.num_batches_tracked\", \"layer3.20.conv3.weight\", \"layer3.20.conv3.bias\", \"layer3.20.batch_norm3.weight\", \"layer3.20.batch_norm3.bias\", \"layer3.20.batch_norm3.running_mean\", \"layer3.20.batch_norm3.running_var\", \"layer3.20.batch_norm3.num_batches_tracked\", \"layer3.21.conv1.weight\", \"layer3.21.conv1.bias\", \"layer3.21.batch_norm1.weight\", \"layer3.21.batch_norm1.bias\", \"layer3.21.batch_norm1.running_mean\", \"layer3.21.batch_norm1.running_var\", \"layer3.21.batch_norm1.num_batches_tracked\", \"layer3.21.conv2.weight\", \"layer3.21.conv2.bias\", \"layer3.21.batch_norm2.weight\", \"layer3.21.batch_norm2.bias\", \"layer3.21.batch_norm2.running_mean\", \"layer3.21.batch_norm2.running_var\", \"layer3.21.batch_norm2.num_batches_tracked\", \"layer3.21.conv3.weight\", \"layer3.21.conv3.bias\", \"layer3.21.batch_norm3.weight\", \"layer3.21.batch_norm3.bias\", \"layer3.21.batch_norm3.running_mean\", \"layer3.21.batch_norm3.running_var\", \"layer3.21.batch_norm3.num_batches_tracked\", \"layer3.22.conv1.weight\", \"layer3.22.conv1.bias\", \"layer3.22.batch_norm1.weight\", \"layer3.22.batch_norm1.bias\", \"layer3.22.batch_norm1.running_mean\", \"layer3.22.batch_norm1.running_var\", \"layer3.22.batch_norm1.num_batches_tracked\", \"layer3.22.conv2.weight\", \"layer3.22.conv2.bias\", \"layer3.22.batch_norm2.weight\", \"layer3.22.batch_norm2.bias\", \"layer3.22.batch_norm2.running_mean\", \"layer3.22.batch_norm2.running_var\", \"layer3.22.batch_norm2.num_batches_tracked\", \"layer3.22.conv3.weight\", \"layer3.22.conv3.bias\", \"layer3.22.batch_norm3.weight\", \"layer3.22.batch_norm3.bias\", \"layer3.22.batch_norm3.running_mean\", \"layer3.22.batch_norm3.running_var\", \"layer3.22.batch_norm3.num_batches_tracked\", \"layer3.23.conv1.weight\", \"layer3.23.conv1.bias\", \"layer3.23.batch_norm1.weight\", \"layer3.23.batch_norm1.bias\", \"layer3.23.batch_norm1.running_mean\", \"layer3.23.batch_norm1.running_var\", \"layer3.23.batch_norm1.num_batches_tracked\", \"layer3.23.conv2.weight\", \"layer3.23.conv2.bias\", \"layer3.23.batch_norm2.weight\", \"layer3.23.batch_norm2.bias\", \"layer3.23.batch_norm2.running_mean\", \"layer3.23.batch_norm2.running_var\", \"layer3.23.batch_norm2.num_batches_tracked\", \"layer3.23.conv3.weight\", \"layer3.23.conv3.bias\", \"layer3.23.batch_norm3.weight\", \"layer3.23.batch_norm3.bias\", \"layer3.23.batch_norm3.running_mean\", \"layer3.23.batch_norm3.running_var\", \"layer3.23.batch_norm3.num_batches_tracked\", \"layer3.24.conv1.weight\", \"layer3.24.conv1.bias\", \"layer3.24.batch_norm1.weight\", \"layer3.24.batch_norm1.bias\", \"layer3.24.batch_norm1.running_mean\", \"layer3.24.batch_norm1.running_var\", \"layer3.24.batch_norm1.num_batches_tracked\", \"layer3.24.conv2.weight\", \"layer3.24.conv2.bias\", \"layer3.24.batch_norm2.weight\", \"layer3.24.batch_norm2.bias\", \"layer3.24.batch_norm2.running_mean\", \"layer3.24.batch_norm2.running_var\", \"layer3.24.batch_norm2.num_batches_tracked\", \"layer3.24.conv3.weight\", \"layer3.24.conv3.bias\", \"layer3.24.batch_norm3.weight\", \"layer3.24.batch_norm3.bias\", \"layer3.24.batch_norm3.running_mean\", \"layer3.24.batch_norm3.running_var\", \"layer3.24.batch_norm3.num_batches_tracked\", \"layer3.25.conv1.weight\", \"layer3.25.conv1.bias\", \"layer3.25.batch_norm1.weight\", \"layer3.25.batch_norm1.bias\", \"layer3.25.batch_norm1.running_mean\", \"layer3.25.batch_norm1.running_var\", \"layer3.25.batch_norm1.num_batches_tracked\", \"layer3.25.conv2.weight\", \"layer3.25.conv2.bias\", \"layer3.25.batch_norm2.weight\", \"layer3.25.batch_norm2.bias\", \"layer3.25.batch_norm2.running_mean\", \"layer3.25.batch_norm2.running_var\", \"layer3.25.batch_norm2.num_batches_tracked\", \"layer3.25.conv3.weight\", \"layer3.25.conv3.bias\", \"layer3.25.batch_norm3.weight\", \"layer3.25.batch_norm3.bias\", \"layer3.25.batch_norm3.running_mean\", \"layer3.25.batch_norm3.running_var\", \"layer3.25.batch_norm3.num_batches_tracked\", \"layer3.26.conv1.weight\", \"layer3.26.conv1.bias\", \"layer3.26.batch_norm1.weight\", \"layer3.26.batch_norm1.bias\", \"layer3.26.batch_norm1.running_mean\", \"layer3.26.batch_norm1.running_var\", \"layer3.26.batch_norm1.num_batches_tracked\", \"layer3.26.conv2.weight\", \"layer3.26.conv2.bias\", \"layer3.26.batch_norm2.weight\", \"layer3.26.batch_norm2.bias\", \"layer3.26.batch_norm2.running_mean\", \"layer3.26.batch_norm2.running_var\", \"layer3.26.batch_norm2.num_batches_tracked\", \"layer3.26.conv3.weight\", \"layer3.26.conv3.bias\", \"layer3.26.batch_norm3.weight\", \"layer3.26.batch_norm3.bias\", \"layer3.26.batch_norm3.running_mean\", \"layer3.26.batch_norm3.running_var\", \"layer3.26.batch_norm3.num_batches_tracked\", \"layer3.27.conv1.weight\", \"layer3.27.conv1.bias\", \"layer3.27.batch_norm1.weight\", \"layer3.27.batch_norm1.bias\", \"layer3.27.batch_norm1.running_mean\", \"layer3.27.batch_norm1.running_var\", \"layer3.27.batch_norm1.num_batches_tracked\", \"layer3.27.conv2.weight\", \"layer3.27.conv2.bias\", \"layer3.27.batch_norm2.weight\", \"layer3.27.batch_norm2.bias\", \"layer3.27.batch_norm2.running_mean\", \"layer3.27.batch_norm2.running_var\", \"layer3.27.batch_norm2.num_batches_tracked\", \"layer3.27.conv3.weight\", \"layer3.27.conv3.bias\", \"layer3.27.batch_norm3.weight\", \"layer3.27.batch_norm3.bias\", \"layer3.27.batch_norm3.running_mean\", \"layer3.27.batch_norm3.running_var\", \"layer3.27.batch_norm3.num_batches_tracked\", \"layer3.28.conv1.weight\", \"layer3.28.conv1.bias\", \"layer3.28.batch_norm1.weight\", \"layer3.28.batch_norm1.bias\", \"layer3.28.batch_norm1.running_mean\", \"layer3.28.batch_norm1.running_var\", \"layer3.28.batch_norm1.num_batches_tracked\", \"layer3.28.conv2.weight\", \"layer3.28.conv2.bias\", \"layer3.28.batch_norm2.weight\", \"layer3.28.batch_norm2.bias\", \"layer3.28.batch_norm2.running_mean\", \"layer3.28.batch_norm2.running_var\", \"layer3.28.batch_norm2.num_batches_tracked\", \"layer3.28.conv3.weight\", \"layer3.28.conv3.bias\", \"layer3.28.batch_norm3.weight\", \"layer3.28.batch_norm3.bias\", \"layer3.28.batch_norm3.running_mean\", \"layer3.28.batch_norm3.running_var\", \"layer3.28.batch_norm3.num_batches_tracked\", \"layer3.29.conv1.weight\", \"layer3.29.conv1.bias\", \"layer3.29.batch_norm1.weight\", \"layer3.29.batch_norm1.bias\", \"layer3.29.batch_norm1.running_mean\", \"layer3.29.batch_norm1.running_var\", \"layer3.29.batch_norm1.num_batches_tracked\", \"layer3.29.conv2.weight\", \"layer3.29.conv2.bias\", \"layer3.29.batch_norm2.weight\", \"layer3.29.batch_norm2.bias\", \"layer3.29.batch_norm2.running_mean\", \"layer3.29.batch_norm2.running_var\", \"layer3.29.batch_norm2.num_batches_tracked\", \"layer3.29.conv3.weight\", \"layer3.29.conv3.bias\", \"layer3.29.batch_norm3.weight\", \"layer3.29.batch_norm3.bias\", \"layer3.29.batch_norm3.running_mean\", \"layer3.29.batch_norm3.running_var\", \"layer3.29.batch_norm3.num_batches_tracked\", \"layer3.30.conv1.weight\", \"layer3.30.conv1.bias\", \"layer3.30.batch_norm1.weight\", \"layer3.30.batch_norm1.bias\", \"layer3.30.batch_norm1.running_mean\", \"layer3.30.batch_norm1.running_var\", \"layer3.30.batch_norm1.num_batches_tracked\", \"layer3.30.conv2.weight\", \"layer3.30.conv2.bias\", \"layer3.30.batch_norm2.weight\", \"layer3.30.batch_norm2.bias\", \"layer3.30.batch_norm2.running_mean\", \"layer3.30.batch_norm2.running_var\", \"layer3.30.batch_norm2.num_batches_tracked\", \"layer3.30.conv3.weight\", \"layer3.30.conv3.bias\", \"layer3.30.batch_norm3.weight\", \"layer3.30.batch_norm3.bias\", \"layer3.30.batch_norm3.running_mean\", \"layer3.30.batch_norm3.running_var\", \"layer3.30.batch_norm3.num_batches_tracked\", \"layer3.31.conv1.weight\", \"layer3.31.conv1.bias\", \"layer3.31.batch_norm1.weight\", \"layer3.31.batch_norm1.bias\", \"layer3.31.batch_norm1.running_mean\", \"layer3.31.batch_norm1.running_var\", \"layer3.31.batch_norm1.num_batches_tracked\", \"layer3.31.conv2.weight\", \"layer3.31.conv2.bias\", \"layer3.31.batch_norm2.weight\", \"layer3.31.batch_norm2.bias\", \"layer3.31.batch_norm2.running_mean\", \"layer3.31.batch_norm2.running_var\", \"layer3.31.batch_norm2.num_batches_tracked\", \"layer3.31.conv3.weight\", \"layer3.31.conv3.bias\", \"layer3.31.batch_norm3.weight\", \"layer3.31.batch_norm3.bias\", \"layer3.31.batch_norm3.running_mean\", \"layer3.31.batch_norm3.running_var\", \"layer3.31.batch_norm3.num_batches_tracked\", \"layer3.32.conv1.weight\", \"layer3.32.conv1.bias\", \"layer3.32.batch_norm1.weight\", \"layer3.32.batch_norm1.bias\", \"layer3.32.batch_norm1.running_mean\", \"layer3.32.batch_norm1.running_var\", \"layer3.32.batch_norm1.num_batches_tracked\", \"layer3.32.conv2.weight\", \"layer3.32.conv2.bias\", \"layer3.32.batch_norm2.weight\", \"layer3.32.batch_norm2.bias\", \"layer3.32.batch_norm2.running_mean\", \"layer3.32.batch_norm2.running_var\", \"layer3.32.batch_norm2.num_batches_tracked\", \"layer3.32.conv3.weight\", \"layer3.32.conv3.bias\", \"layer3.32.batch_norm3.weight\", \"layer3.32.batch_norm3.bias\", \"layer3.32.batch_norm3.running_mean\", \"layer3.32.batch_norm3.running_var\", \"layer3.32.batch_norm3.num_batches_tracked\", \"layer3.33.conv1.weight\", \"layer3.33.conv1.bias\", \"layer3.33.batch_norm1.weight\", \"layer3.33.batch_norm1.bias\", \"layer3.33.batch_norm1.running_mean\", \"layer3.33.batch_norm1.running_var\", \"layer3.33.batch_norm1.num_batches_tracked\", \"layer3.33.conv2.weight\", \"layer3.33.conv2.bias\", \"layer3.33.batch_norm2.weight\", \"layer3.33.batch_norm2.bias\", \"layer3.33.batch_norm2.running_mean\", \"layer3.33.batch_norm2.running_var\", \"layer3.33.batch_norm2.num_batches_tracked\", \"layer3.33.conv3.weight\", \"layer3.33.conv3.bias\", \"layer3.33.batch_norm3.weight\", \"layer3.33.batch_norm3.bias\", \"layer3.33.batch_norm3.running_mean\", \"layer3.33.batch_norm3.running_var\", \"layer3.33.batch_norm3.num_batches_tracked\", \"layer3.34.conv1.weight\", \"layer3.34.conv1.bias\", \"layer3.34.batch_norm1.weight\", \"layer3.34.batch_norm1.bias\", \"layer3.34.batch_norm1.running_mean\", \"layer3.34.batch_norm1.running_var\", \"layer3.34.batch_norm1.num_batches_tracked\", \"layer3.34.conv2.weight\", \"layer3.34.conv2.bias\", \"layer3.34.batch_norm2.weight\", \"layer3.34.batch_norm2.bias\", \"layer3.34.batch_norm2.running_mean\", \"layer3.34.batch_norm2.running_var\", \"layer3.34.batch_norm2.num_batches_tracked\", \"layer3.34.conv3.weight\", \"layer3.34.conv3.bias\", \"layer3.34.batch_norm3.weight\", \"layer3.34.batch_norm3.bias\", \"layer3.34.batch_norm3.running_mean\", \"layer3.34.batch_norm3.running_var\", \"layer3.34.batch_norm3.num_batches_tracked\", \"layer3.35.conv1.weight\", \"layer3.35.conv1.bias\", \"layer3.35.batch_norm1.weight\", \"layer3.35.batch_norm1.bias\", \"layer3.35.batch_norm1.running_mean\", \"layer3.35.batch_norm1.running_var\", \"layer3.35.batch_norm1.num_batches_tracked\", \"layer3.35.conv2.weight\", \"layer3.35.conv2.bias\", \"layer3.35.batch_norm2.weight\", \"layer3.35.batch_norm2.bias\", \"layer3.35.batch_norm2.running_mean\", \"layer3.35.batch_norm2.running_var\", \"layer3.35.batch_norm2.num_batches_tracked\", \"layer3.35.conv3.weight\", \"layer3.35.conv3.bias\", \"layer3.35.batch_norm3.weight\", \"layer3.35.batch_norm3.bias\", \"layer3.35.batch_norm3.running_mean\", \"layer3.35.batch_norm3.running_var\", \"layer3.35.batch_norm3.num_batches_tracked\". \r\n"
     ]
    }
   ],
   "source": [
    "# 检查是否已解压，若未解压则解压文件\n",
    "import os\n",
    "if not os.path.exists('/kaggle/working/train'):\n",
    "     !unzip -q /kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip -d /kaggle/working\n",
    "else:\n",
    "     print(\"【训练集】已经解压过了，不需要再次解压。\")\n",
    "        \n",
    "if not os.path.exists('/kaggle/working/test'):\n",
    "     !unzip -q /kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip -d /kaggle/working\n",
    "else:\n",
    "     print(\"【测试集】已经解压过了，不需要再次解压。\")\n",
    "        \n",
    "!python /kaggle/input/resnet2/pytorch/default/1/catvsdog/train.py --train_dir /kaggle/working/train --batch_size 64 --num_epochs 100 --save_path /kaggle/working/best_resnet152_cats_dogs.pth\n",
    "!python /kaggle/input/resnet2/pytorch/default/1/catvsdog/test.py --test_dir /kaggle/working/test --batch_size 64 --model_path /kaggle/working/best_resnet152_cats_dogs.pth"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 38425,
     "sourceId": 5441,
     "sourceType": "competition"
    },
    {
     "modelId": 114432,
     "modelInstanceId": 90206,
     "sourceId": 107690,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35968.692517,
   "end_time": "2024-09-05T13:57:12.581379",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-05T03:57:43.888862",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
